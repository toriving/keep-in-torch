{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 28 15:54:12 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                  Off |\r\n",
      "| N/A   31C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:1B:00.0 Off |                  Off |\r\n",
      "| N/A   34C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:3D:00.0 Off |                  Off |\r\n",
      "| N/A   33C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:3E:00.0 Off |                  Off |\r\n",
      "| N/A   32C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:88:00.0 Off |                  Off |\r\n",
      "| N/A   33C    P0    42W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                  Off |\r\n",
      "| N/A   35C    P0    45W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                  Off |\r\n",
      "| N/A   34C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                  Off |\r\n",
      "| N/A   31C    P0    41W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(4, 128)\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "        self.affine2 = nn.Linear(128, 2)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.affine1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributed.rpc import rpc_sync\n",
    "\n",
    "def _call_method(method, rref, *args, **kwargs):\n",
    "    return method(rref.local_value(), *args, **kwargs)\n",
    "\n",
    "\n",
    "def _remote_method(method, rref, *args, **kwargs):\n",
    "    args = [method, rref] + list(args)\n",
    "    return rpc_sync(rref.owner(), _call_method, args=args, kwargs=kwargs)\n",
    "\n",
    "# to call a function on an rref, we could do the following\n",
    "# _remote_method(some_func, rref, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--world_size WORLD_SIZE]\n",
      "                             [--log_interval LOG_INTERVAL] [--gamma GAMMA]\n",
      "                             [--seed SEED]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-361ffde2-8ea6-464b-8349-8c3a15ca19e6.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import gym\n",
    "import torch.distributed.rpc as rpc\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"RPC Reinforcement Learning Example\",\n",
    "    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n",
    ")\n",
    "\n",
    "parser.add_argument('--world_size', default=2, help='Number of workers')\n",
    "parser.add_argument('--log_interval', default=1, help='Log every log_interval episodes')\n",
    "parser.add_argument('--gamma', default=0.1, help='how much to value future rewards')\n",
    "parser.add_argument('--seed', default=1, help='random seed for reproducibility')\n",
    "args = parser.parse_args()\n",
    "\n",
    "class Observer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.id = rpc.get_worker_info().id\n",
    "        self.env = gym.make('CartPole-v1')\n",
    "        self.env.seed(args.seed)\n",
    "\n",
    "    def run_episode(self, agent_rref, n_steps):\n",
    "        state, ep_reward = self.env.reset(), 0\n",
    "        for step in range(n_steps):\n",
    "            # send the state to the agent to get an action\n",
    "            action = _remote_method(Agent.select_action, agent_rref, self.id, state)\n",
    "\n",
    "            # apply the action to the environment, and get the reward\n",
    "            state, reward, done, _ = self.env.step(action)\n",
    "\n",
    "            # report the reward to the agent for training purpose\n",
    "            _remote_method(Agent.report_reward, agent_rref, self.id, reward)\n",
    "\n",
    "            if done:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.distributed.rpc as rpc\n",
    "import torch.optim as optim\n",
    "from torch.distributed.rpc import RRef, rpc_async, remote\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, world_size):\n",
    "        self.ob_rrefs = []\n",
    "        self.agent_rref = RRef(self)\n",
    "        self.rewards = {}\n",
    "        self.saved_log_probs = {}\n",
    "        self.policy = Policy()\n",
    "        self.optimizer = optim.Adam(self.policy.parameters(), lr=1e-2)\n",
    "        self.eps = np.finfo(np.float32).eps.item()\n",
    "        self.running_reward = 0\n",
    "        self.reward_threshold = gym.make('CartPole-v1').spec.reward_threshold\n",
    "        for ob_rank in range(1, world_size):\n",
    "            ob_info = rpc.get_worker_info(OBSERVER_NAME.format(ob_rank))\n",
    "            self.ob_rrefs.append(remote(ob_info, Observer))\n",
    "            self.rewards[ob_info.id] = []\n",
    "            self.saved_log_probs[ob_info.id] = []\n",
    "            \n",
    "    def select_action(self, ob_id, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        probs = self.policy(state)\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        self.saved_log_probs[ob_id].append(m.log_prob(action))\n",
    "        return action.item()\n",
    "\n",
    "    def report_reward(self, ob_id, reward):\n",
    "        self.rewards[ob_id].append(reward)\n",
    "        \n",
    "    def run_episode(self, n_steps=0):\n",
    "        futs = []\n",
    "        for ob_rref in self.ob_rrefs:\n",
    "            # make async RPC to kick off an episode on all observers\n",
    "            futs.append(\n",
    "                rpc_async(\n",
    "                    ob_rref.owner(),\n",
    "                    _call_method,\n",
    "                    args=(Observer.run_episode, ob_rref, self.agent_rref, n_steps)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # wait until all obervers have finished this episode\n",
    "        for fut in futs:\n",
    "            fut.wait()\n",
    "\n",
    "    def finish_episode(self):\n",
    "      # joins probs and rewards from different observers into lists\n",
    "      R, probs, rewards = 0, [], []\n",
    "      for ob_id in self.rewards:\n",
    "          probs.extend(self.saved_log_probs[ob_id])\n",
    "          rewards.extend(self.rewards[ob_id])\n",
    "\n",
    "      # use the minimum observer reward to calculate the running reward\n",
    "      min_reward = min([sum(self.rewards[ob_id]) for ob_id in self.rewards])\n",
    "      self.running_reward = 0.05 * min_reward + (1 - 0.05) * self.running_reward\n",
    "\n",
    "      # clear saved probs and rewards\n",
    "      for ob_id in self.rewards:\n",
    "          self.rewards[ob_id] = []\n",
    "          self.saved_log_probs[ob_id] = []\n",
    "\n",
    "      policy_loss, returns = [], []\n",
    "      for r in rewards[::-1]:\n",
    "          R = r + args.gamma * R\n",
    "          returns.insert(0, R)\n",
    "      returns = torch.tensor(returns)\n",
    "      returns = (returns - returns.mean()) / (returns.std() + self.eps)\n",
    "      for log_prob, R in zip(probs, returns):\n",
    "          policy_loss.append(-log_prob * R)\n",
    "      self.optimizer.zero_grad()\n",
    "      policy_loss = torch.cat(policy_loss).sum()\n",
    "      policy_loss.backward()\n",
    "      self.optimizer.step()\n",
    "      return min_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "process 5 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8a404e4e0f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    197\u001b[0m                ' torch.multiprocessing.start_process(...)' % start_method)\n\u001b[1;32m    198\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 raise Exception(\n\u001b[1;32m    111\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 )\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: process 5 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import count\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "AGENT_NAME = \"agent\"\n",
    "OBSERVER_NAME=\"obs\"\n",
    "TOTAL_EPISODE_STEP = 100\n",
    "\n",
    "def run_worker(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    if rank == 0:\n",
    "        # rank0 is the agent\n",
    "        rpc.init_rpc(AGENT_NAME, rank=rank, world_size=world_size)\n",
    "\n",
    "        agent = Agent(world_size)\n",
    "        for i_episode in count(1):\n",
    "            n_steps = int(TOTAL_EPISODE_STEP / (args.world_size - 1))\n",
    "            agent.run_episode(n_steps=n_steps)\n",
    "            last_reward = agent.finish_episode()\n",
    "\n",
    "            if i_episode % args.log_interval == 0:\n",
    "                print('Episode {}\\tLast reward: {:.2f}\\tAverage reward: {:.2f}'.format(\n",
    "                      i_episode, last_reward, agent.running_reward))\n",
    "\n",
    "            if agent.running_reward > agent.reward_threshold:\n",
    "                print(\"Solved! Running reward is now {}!\".format(agent.running_reward))\n",
    "                break\n",
    "    else:\n",
    "        # other ranks are the observer\n",
    "        rpc.init_rpc(OBSERVER_NAME.format(rank), rank=rank, world_size=world_size)\n",
    "        # observers passively waiting for instructions from the agent\n",
    "\n",
    "    # block until all rpcs finish, and shutdown the RPC instance\n",
    "    rpc.shutdown()\n",
    "\n",
    "\n",
    "mp.spawn(\n",
    "    run_worker,\n",
    "    args=(8, ),\n",
    "    nprocs=8,\n",
    "    join=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTable(nn.Module):\n",
    "    r\"\"\"\n",
    "    Encoding layers of the RNNModel\n",
    "    \"\"\"\n",
    "    def __init__(self, ntoken, ninp, dropout):\n",
    "        super(EmbeddingTable, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp).cuda()\n",
    "        self.encoder.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.drop(self.encoder(input.cuda()).cpu())\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, ntoken, nhid, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, output):\n",
    "        return self.decoder(self.drop(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, ps, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # setup embedding table remotely\n",
    "        self.emb_table_rref = rpc.remote(ps, EmbeddingTable, args=(ntoken, ninp, dropout))\n",
    "        # setup LSTM locally\n",
    "        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout)\n",
    "        # setup decoder remotely\n",
    "        self.decoder_rref = rpc.remote(ps, Decoder, args=(ntoken, nhid, dropout))\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # pass input to the remote embedding table and fetch emb tensor back\n",
    "        emb = _remote_method(EmbeddingTable.forward, self.emb_table_rref, input)\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        # pass output to the rremote decoder and get the decoded output back\n",
    "        decoded = _remote_method(Decoder.forward, self.decoder_rref, output)\n",
    "        return decoded, hidden\n",
    "\n",
    "    def parameter_rrefs(self):\n",
    "        remote_params = []\n",
    "        # get RRefs of embedding table\n",
    "        remote_params.extend(_remote_method(_parameter_rrefs, self.emb_table_rref))\n",
    "        # create RRefs for local parameters\n",
    "        remote_params.extend(_parameter_rrefs(self.rnn))\n",
    "        # get RRefs of decoder\n",
    "        remote_params.extend(_remote_method(_parameter_rrefs, self.decoder_rref))\n",
    "        return remote_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parameter_rrefs(module):\n",
    "    param_rrefs = []\n",
    "    for param in module.parameters():\n",
    "        param_rrefs.append(RRef(param))\n",
    "    return param_rrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trainer():\n",
    "    batch = 5\n",
    "    ntoken = 10\n",
    "    ninp = 2\n",
    "\n",
    "    nhid = 3\n",
    "    nindices = 3\n",
    "    nlayers = 4\n",
    "    hidden = (\n",
    "        torch.randn(nlayers, nindices, nhid),\n",
    "        torch.randn(nlayers, nindices, nhid)\n",
    "    )\n",
    "\n",
    "    model = rnn.RNNModel('ps', ntoken, ninp, nhid, nlayers)\n",
    "\n",
    "    # setup distributed optimizer\n",
    "    opt = DistributedOptimizer(\n",
    "        optim.SGD,\n",
    "        model.parameter_rrefs(),\n",
    "        lr=0.05,\n",
    "    )\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def get_next_batch():\n",
    "        for _ in range(5):\n",
    "            data = torch.LongTensor(batch, nindices) % ntoken\n",
    "            target = torch.LongTensor(batch, ntoken) % nindices\n",
    "            yield data, target\n",
    "\n",
    "    # train for 10 iterations\n",
    "    for epoch in range(10):\n",
    "        for data, target in get_next_batch():\n",
    "            # create distributed autograd context\n",
    "            with dist_autograd.context() as context_id:\n",
    "                hidden[0].detach_()\n",
    "                hidden[1].detach_()\n",
    "                output, hidden = model(data, hidden)\n",
    "                loss = criterion(output, target)\n",
    "                # run distributed backward pass\n",
    "                dist_autograd.backward(context_id, [loss])\n",
    "                # run distributed optimizer\n",
    "                opt.step(context_id)\n",
    "                # not necessary to zero grads since they are\n",
    "                # accumulated into the distributed autograd context\n",
    "                # which is reset every iteration.\n",
    "        print(\"Training epoch {}\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_worker(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    if rank == 1:\n",
    "        rpc.init_rpc(\"trainer\", rank=rank, world_size=world_size)\n",
    "        _run_trainer()\n",
    "    else:\n",
    "        rpc.init_rpc(\"ps\", rank=rank, world_size=world_size)\n",
    "        # parameter server do nothing\n",
    "        pass\n",
    "\n",
    "    # block until all rpcs finish\n",
    "    rpc.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9d502d3a5bbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mworld_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    197\u001b[0m                ' torch.multiprocessing.start_process(...)' % start_method)\n\u001b[1;32m    198\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 raise Exception(\n\u001b[1;32m    111\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 )\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    world_size = 2\n",
    "    mp.spawn(run_worker, args=(world_size, ), nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
