{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 28 15:52:48 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:1A:00.0 Off |                  Off |\r\n",
      "| N/A   31C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:1B:00.0 Off |                  Off |\r\n",
      "| N/A   34C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:3D:00.0 Off |                  Off |\r\n",
      "| N/A   33C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:3E:00.0 Off |                  Off |\r\n",
      "| N/A   32C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:88:00.0 Off |                  Off |\r\n",
      "| N/A   33C    P0    42W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                  Off |\r\n",
      "| N/A   35C    P0    45W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                  Off |\r\n",
      "| N/A   34C    P0    43W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                  Off |\r\n",
      "| N/A   31C    P0    41W / 300W |     12MiB / 32510MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                Version            \r\n",
      "---------------------- -------------------\r\n",
      "absl-py                0.9.0              \r\n",
      "asn1crypto             1.3.0              \r\n",
      "attrs                  19.3.0             \r\n",
      "backcall               0.1.0              \r\n",
      "bleach                 3.1.1              \r\n",
      "boto                   2.49.0             \r\n",
      "boto3                  1.12.15            \r\n",
      "botocore               1.15.15            \r\n",
      "cachetools             4.0.0              \r\n",
      "certifi                2019.11.28         \r\n",
      "cffi                   1.14.0             \r\n",
      "chardet                3.0.4              \r\n",
      "Click                  7.0                \r\n",
      "cloudpickle            1.3.0              \r\n",
      "conda                  4.8.2              \r\n",
      "conda-package-handling 1.6.0              \r\n",
      "cryptography           2.8                \r\n",
      "cycler                 0.10.0             \r\n",
      "Cython                 0.29.15            \r\n",
      "dataclasses            0.7                \r\n",
      "decorator              4.4.1              \r\n",
      "defusedxml             0.6.0              \r\n",
      "docutils               0.15.2             \r\n",
      "entrypoints            0.3                \r\n",
      "Flask                  1.1.1              \r\n",
      "future                 0.18.2             \r\n",
      "gensim                 3.8.1              \r\n",
      "google-auth            1.11.2             \r\n",
      "google-auth-oauthlib   0.4.1              \r\n",
      "grpcio                 1.27.2             \r\n",
      "gym                    0.17.1             \r\n",
      "h5py                   2.10.0             \r\n",
      "idna                   2.8                \r\n",
      "imageio                2.8.0              \r\n",
      "importlib-metadata     1.5.0              \r\n",
      "ipykernel              5.1.4              \r\n",
      "ipython                7.12.0             \r\n",
      "ipython-genutils       0.2.0              \r\n",
      "ipywidgets             7.5.1              \r\n",
      "itsdangerous           1.1.0              \r\n",
      "jedi                   0.16.0             \r\n",
      "Jinja2                 2.11.1             \r\n",
      "jmespath               0.9.5              \r\n",
      "joblib                 0.14.1             \r\n",
      "jsonschema             3.2.0              \r\n",
      "jupyter                1.0.0              \r\n",
      "jupyter-client         6.0.0              \r\n",
      "jupyter-console        6.1.0              \r\n",
      "jupyter-core           4.6.3              \r\n",
      "Keras                  2.3.1              \r\n",
      "Keras-Applications     1.0.8              \r\n",
      "Keras-Preprocessing    1.1.0              \r\n",
      "kiwisolver             1.1.0              \r\n",
      "Markdown               3.2.1              \r\n",
      "MarkupSafe             1.1.1              \r\n",
      "matplotlib             3.2.0              \r\n",
      "mistune                0.8.4              \r\n",
      "mkl-fft                1.0.15             \r\n",
      "mkl-random             1.1.0              \r\n",
      "mkl-service            2.3.0              \r\n",
      "mpmath                 1.1.0              \r\n",
      "nbconvert              5.6.1              \r\n",
      "nbformat               5.0.4              \r\n",
      "networkx               2.4                \r\n",
      "notebook               6.0.3              \r\n",
      "numpy                  1.18.1             \r\n",
      "oauthlib               3.1.0              \r\n",
      "olefile                0.46               \r\n",
      "onnx                   1.6.0              \r\n",
      "opencv-python          4.2.0.32           \r\n",
      "pandas                 1.0.1              \r\n",
      "pandocfilters          1.4.2              \r\n",
      "parso                  0.6.1              \r\n",
      "pexpect                4.8.0              \r\n",
      "pickleshare            0.7.5              \r\n",
      "Pillow                 7.0.0              \r\n",
      "pip                    20.0.2             \r\n",
      "prometheus-client      0.7.1              \r\n",
      "prompt-toolkit         3.0.3              \r\n",
      "protobuf               3.11.3             \r\n",
      "ptyprocess             0.6.0              \r\n",
      "pyasn1                 0.4.8              \r\n",
      "pyasn1-modules         0.2.8              \r\n",
      "pycosat                0.6.3              \r\n",
      "pycparser              2.19               \r\n",
      "pyglet                 1.5.0              \r\n",
      "Pygments               2.5.2              \r\n",
      "pyOpenSSL              19.1.0             \r\n",
      "pyparsing              2.4.6              \r\n",
      "pyrsistent             0.15.7             \r\n",
      "PySocks                1.7.1              \r\n",
      "python-dateutil        2.8.1              \r\n",
      "pytz                   2019.3             \r\n",
      "PyWavelets             1.1.1              \r\n",
      "PyYAML                 5.3                \r\n",
      "pyzmq                  19.0.0             \r\n",
      "qtconsole              4.7.1              \r\n",
      "QtPy                   1.9.0              \r\n",
      "requests               2.22.0             \r\n",
      "requests-oauthlib      1.3.0              \r\n",
      "rsa                    4.0                \r\n",
      "ruamel-yaml            0.15.87            \r\n",
      "s3transfer             0.3.3              \r\n",
      "scikit-image           0.16.2             \r\n",
      "scikit-learn           0.22.2.post1       \r\n",
      "scipy                  1.4.1              \r\n",
      "Send2Trash             1.5.0              \r\n",
      "setuptools             45.2.0.post20200210\r\n",
      "six                    1.14.0             \r\n",
      "sklearn                0.0                \r\n",
      "smart-open             1.9.0              \r\n",
      "sympy                  1.5.1              \r\n",
      "tensorboard            2.1.1              \r\n",
      "terminado              0.8.3              \r\n",
      "testpath               0.4.4              \r\n",
      "tflearn                0.3.2              \r\n",
      "torch                  1.7.0              \r\n",
      "torchvision            0.5.0              \r\n",
      "tornado                6.0.4              \r\n",
      "tqdm                   4.36.1             \r\n",
      "traitlets              4.3.3              \r\n",
      "typing                 3.6.4              \r\n",
      "typing-extensions      3.7.4.1            \r\n",
      "Unidecode              1.1.1              \r\n",
      "urllib3                1.25.8             \r\n",
      "wcwidth                0.1.8              \r\n",
      "webencodings           0.5.1              \r\n",
      "Werkzeug               1.0.0              \r\n",
      "wheel                  0.34.2             \r\n",
      "widgetsnbextension     3.5.1              \r\n",
      "zipp                   3.1.0              \r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.multiprocessing import Process\n",
    "\n",
    "def run(rank, size):\n",
    "    \"\"\" Distributed function to be implemented later. \"\"\"\n",
    "    pass\n",
    "\n",
    "def init_process(rank, size, fn, backend='gloo'):\n",
    "    \"\"\" Initialize the distributed environment. \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "    os.environ['MASTER_PORT'] = '29500'\n",
    "    dist.init_process_group(backend, rank=rank, world_size=size)\n",
    "    fn(rank, size)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    size = 2\n",
    "    processes = []\n",
    "    for rank in range(size):\n",
    "        p = Process(target=init_process, args=(rank, size, run))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank, size):\n",
    "    tensor = torch.zeros(1)\n",
    "    if rank == 0:\n",
    "        tensor += 1\n",
    "        # Send the tensor to process 1\n",
    "        dist.send(tensor=tensor, dst=1)\n",
    "    else:\n",
    "        # Receive tensor from process 0\n",
    "        dist.recv(tensor=tensor, src=0)\n",
    "    print('Rank ', rank, ' has data ', tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank, size):\n",
    "    tensor = torch.zeros(1)\n",
    "    req = None\n",
    "    if rank == 0:\n",
    "        tensor += 1\n",
    "        # Send the tensor to process 1\n",
    "        req = dist.isend(tensor=tensor, dst=1)\n",
    "        print('Rank 0 started sending')\n",
    "    else:\n",
    "        # Receive tensor from process 0\n",
    "        req = dist.irecv(tensor=tensor, src=0)\n",
    "        print('Rank 1 started receiving')\n",
    "    req.wait()\n",
    "    print('Rank ', rank, ' has data ', tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank, size):\n",
    "    \"\"\" Simple point-to-point communication. \"\"\"\n",
    "    group = dist.new_group([0, 1])\n",
    "    tensor = torch.ones(1)\n",
    "    dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group)\n",
    "    print('Rank ', rank, ' has data ', tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Partition(object):\n",
    "\n",
    "    def __init__(self, data, index):\n",
    "        self.data = data\n",
    "        self.index = index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_idx = self.index[index]\n",
    "        return self.data[data_idx]\n",
    "\n",
    "\n",
    "class DataPartitioner(object):\n",
    "\n",
    "    def __init__(self, data, sizes=[0.7, 0.2, 0.1], seed=1234):\n",
    "        self.data = data\n",
    "        self.partitions = []\n",
    "        rng = Random()\n",
    "        rng.seed(seed)\n",
    "        data_len = len(data)\n",
    "        indexes = [x for x in range(0, data_len)]\n",
    "        rng.shuffle(indexes)\n",
    "\n",
    "        for frac in sizes:\n",
    "            part_len = int(frac * data_len)\n",
    "            self.partitions.append(indexes[0:part_len])\n",
    "            indexes = indexes[part_len:]\n",
    "\n",
    "    def use(self, partition):\n",
    "        return Partition(self.data, self.partitions[partition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset():\n",
    "    dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "    size = dist.get_world_size()\n",
    "    bsz = 128 / float(size)\n",
    "    partition_sizes = [1.0 / size for _ in range(size)]\n",
    "    partition = DataPartitioner(dataset, partition_sizes)\n",
    "    partition = partition.use(dist.get_rank())\n",
    "    train_set = torch.utils.data.DataLoader(partition,\n",
    "                                         batch_size=bsz,\n",
    "                                         shuffle=True)\n",
    "    return train_set, bsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(rank, size):\n",
    "    torch.manual_seed(1234)\n",
    "    train_set, bsz = partition_dataset()\n",
    "    model = Net()\n",
    "    optimizer = optim.SGD(model.parameters(),\n",
    "                          lr=0.01, momentum=0.5)\n",
    "\n",
    "    num_batches = ceil(len(train_set.dataset) / float(bsz))\n",
    "    for epoch in range(10):\n",
    "        epoch_loss = 0.0\n",
    "        for data, target in train_set:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            average_gradients(model)\n",
    "            optimizer.step()\n",
    "        print('Rank ', dist.get_rank(), ', epoch ',\n",
    "              epoch, ': ', epoch_loss / num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradients(model):\n",
    "    size = float(dist.get_world_size())\n",
    "    for param in model.parameters():\n",
    "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM)\n",
    "        param.grad.data /= size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allreduce(send, recv):\n",
    "   rank = dist.get_rank()\n",
    "   size = dist.get_world_size()\n",
    "   send_buff = send.clone()\n",
    "   recv_buff = send.clone()\n",
    "   accum = send.clone()\n",
    "\n",
    "   left = ((rank - 1) + size) % size\n",
    "   right = (rank + 1) % size\n",
    "\n",
    "   for i in range(size - 1):\n",
    "       if i % 2 == 0:\n",
    "           # Send send_buff\n",
    "           send_req = dist.isend(send_buff, right)\n",
    "           dist.recv(recv_buff, left)\n",
    "           accum[:] += recv_buff[:]\n",
    "       else:\n",
    "           # Send recv_buff\n",
    "           send_req = dist.isend(recv_buff, right)\n",
    "           dist.recv(send_buff, left)\n",
    "           accum[:] += send_buff[:]\n",
    "       send_req.wait()\n",
    "   recv[:] = accum[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
