{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "torchtext_translation_tutorial.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7HCvCpLP3np"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYniUMreQeGr",
        "outputId": "848d3dc8-d9ed-4d8f-e330-cfa96e335ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "!pip install --upgrade torchtext"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f9/224b3893ab11d83d47fde357a7dcc75f00ba219f34f3d15e06fe4cb62e05/torchtext-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 4.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5NxiEppP3ns"
      },
      "source": [
        "\n",
        "Language Translation with TorchText\n",
        "===================================\n",
        "\n",
        "This tutorial shows how to use several convenience classes of ``torchtext`` to preprocess\n",
        "data from a well-known dataset containing sentences in both English and German and use it to\n",
        "train a sequence-to-sequence model with attention that can translate German sentences\n",
        "into English.\n",
        "\n",
        "It is based off of\n",
        "`this tutorial <https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb>`__\n",
        "from PyTorch community member `Ben Trevett <https://github.com/bentrevett>`__\n",
        "and was created by `Seth Weidman <https://github.com/SethHWeidman/>`__ with Ben's permission.\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "\n",
        "- Preprocess sentences into a commonly-used format for NLP modeling using the following ``torchtext`` convenience classes:\n",
        "    - `TranslationDataset <https://torchtext.readthedocs.io/en/latest/datasets.html#torchtext.datasets.TranslationDataset>`__\n",
        "    - `Field <https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Field>`__\n",
        "    - `BucketIterator <https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.BucketIterator>`__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cONDdG1HP3nt"
      },
      "source": [
        "`Field` and `TranslationDataset`\n",
        "----------------\n",
        "``torchtext`` has utilities for creating datasets that can be easily\n",
        "iterated through for the purposes of creating a language translation\n",
        "model. One key class is a\n",
        "`Field <https://github.com/pytorch/text/blob/master/torchtext/data/field.py#L64>`__,\n",
        "which specifies the way each sentence should be preprocessed, and another is the\n",
        "`TranslationDataset` ; ``torchtext``\n",
        "has several such datasets; in this tutorial we'll use the\n",
        "`Multi30k dataset <https://github.com/multi30k/dataset>`__, which contains about\n",
        "30,000 sentences (averaging about 13 words in length) in both English and German.\n",
        "\n",
        "Note: the tokenization in this tutorial requires `Spacy <https://spacy.io>`__\n",
        "We use Spacy because it provides strong support for tokenization in languages\n",
        "other than English. ``torchtext`` provides a ``basic_english`` tokenizer\n",
        "and supports other tokenizers for English (e.g.\n",
        "`Moses <https://bitbucket.org/luismsgomes/mosestokenizer/src/default/>`__)\n",
        "but for language translation - where multiple languages are required -\n",
        "Spacy is your best bet.\n",
        "\n",
        "To run this tutorial, first install ``spacy`` using ``pip`` or ``conda``.\n",
        "Next, download the raw data for the English and German Spacy tokenizers:\n",
        "\n",
        "::\n",
        "\n",
        "   python -m spacy download en\n",
        "   python -m spacy download de\n",
        "\n",
        "With Spacy installed, the following code will tokenize each of the sentences\n",
        "in the ``TranslationDataset`` based on the tokenizer defined in the ``Field``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g15MU02fQP3H",
        "outputId": "72702bb3-c574-431d-a7e9-91e9266a1e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.2.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjAOoyeNP3nt",
        "outputId": "b7ce07ea-008c-4184-cdee-6c0b4e56ab17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "SRC = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"de\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"en\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n",
        "                                                    fields = (SRC, TRG))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 494kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 172kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 162kB/s]\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLAWr94KP3nv"
      },
      "source": [
        "Now that we've defined ``train_data``, we can see an extremely useful\n",
        "feature of ``torchtext``'s ``Field``: the ``build_vocab`` method\n",
        "now allows us to create the vocabulary associated with each language\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvfRrZmTP3nv"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV5zOoCrRNVB",
        "outputId": "f2fdd457-902d-47a9-823c-85577b48b8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "SRC.vocab.stoi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f0d2b182908>>,\n",
              "            {'<unk>': 0,\n",
              "             '<pad>': 1,\n",
              "             '<sos>': 2,\n",
              "             '<eos>': 3,\n",
              "             '.': 4,\n",
              "             'ein': 5,\n",
              "             'einem': 6,\n",
              "             'in': 7,\n",
              "             'eine': 8,\n",
              "             ',': 9,\n",
              "             'und': 10,\n",
              "             'mit': 11,\n",
              "             'auf': 12,\n",
              "             'mann': 13,\n",
              "             'einer': 14,\n",
              "             'der': 15,\n",
              "             'frau': 16,\n",
              "             'die': 17,\n",
              "             'zwei': 18,\n",
              "             'einen': 19,\n",
              "             'im': 20,\n",
              "             'an': 21,\n",
              "             'von': 22,\n",
              "             'sich': 23,\n",
              "             'dem': 24,\n",
              "             'mädchen': 25,\n",
              "             'junge': 26,\n",
              "             'vor': 27,\n",
              "             'zu': 28,\n",
              "             'steht': 29,\n",
              "             'männer': 30,\n",
              "             'sitzt': 31,\n",
              "             'hund': 32,\n",
              "             'den': 33,\n",
              "             'straße': 34,\n",
              "             'während': 35,\n",
              "             'gruppe': 36,\n",
              "             'hält': 37,\n",
              "             'spielt': 38,\n",
              "             'das': 39,\n",
              "             'hemd': 40,\n",
              "             'personen': 41,\n",
              "             'über': 42,\n",
              "             'drei': 43,\n",
              "             'eines': 44,\n",
              "             'frauen': 45,\n",
              "             'blauen': 46,\n",
              "             'neben': 47,\n",
              "             'ist': 48,\n",
              "             'kind': 49,\n",
              "             'roten': 50,\n",
              "             'weißen': 51,\n",
              "             'stehen': 52,\n",
              "             'sitzen': 53,\n",
              "             'menschen': 54,\n",
              "             'am': 55,\n",
              "             'aus': 56,\n",
              "             'spielen': 57,\n",
              "             'durch': 58,\n",
              "             'bei': 59,\n",
              "             'geht': 60,\n",
              "             'trägt': 61,\n",
              "             'fährt': 62,\n",
              "             'wasser': 63,\n",
              "             'um': 64,\n",
              "             'kinder': 65,\n",
              "             'kleines': 66,\n",
              "             'person': 67,\n",
              "             'macht': 68,\n",
              "             'springt': 69,\n",
              "             'kleiner': 70,\n",
              "             'schwarzen': 71,\n",
              "             'entlang': 72,\n",
              "             'leute': 73,\n",
              "             'gehen': 74,\n",
              "             'etwas': 75,\n",
              "             'mehrere': 76,\n",
              "             'seinem': 77,\n",
              "             'großen': 78,\n",
              "             'oberteil': 79,\n",
              "             'jungen': 80,\n",
              "             'hand': 81,\n",
              "             'grünen': 82,\n",
              "             'läuft': 83,\n",
              "             'sind': 84,\n",
              "             'für': 85,\n",
              "             'hintergrund': 86,\n",
              "             'fahrrad': 87,\n",
              "             'freien': 88,\n",
              "             'jacke': 89,\n",
              "             'luft': 90,\n",
              "             'strand': 91,\n",
              "             'ball': 92,\n",
              "             'hat': 93,\n",
              "             'anderen': 94,\n",
              "             'schaut': 95,\n",
              "             'junger': 96,\n",
              "             'kleidung': 97,\n",
              "             'hinter': 98,\n",
              "             'sie': 99,\n",
              "             'nach': 100,\n",
              "             'andere': 101,\n",
              "             'gelben': 102,\n",
              "             'kleine': 103,\n",
              "             'gebäude': 104,\n",
              "             'vier': 105,\n",
              "             'hut': 106,\n",
              "             'tisch': 107,\n",
              "             'wird': 108,\n",
              "             'beim': 109,\n",
              "             'nähe': 110,\n",
              "             'essen': 111,\n",
              "             'kleinen': 112,\n",
              "             'menschenmenge': 113,\n",
              "             'schwarzer': 114,\n",
              "             'kamera': 115,\n",
              "             'paar': 116,\n",
              "             'vorbei': 117,\n",
              "             'gras': 118,\n",
              "             'hoch': 119,\n",
              "             't-shirt': 120,\n",
              "             'hunde': 121,\n",
              "             'boden': 122,\n",
              "             'schnee': 123,\n",
              "             'rennt': 124,\n",
              "             'ihre': 125,\n",
              "             'unter': 126,\n",
              "             'ihren': 127,\n",
              "             'kleid': 128,\n",
              "             'gitarre': 129,\n",
              "             'älterer': 130,\n",
              "             'draußen': 131,\n",
              "             'sein': 132,\n",
              "             'zusammen': 133,\n",
              "             'ihr': 134,\n",
              "             'feld': 135,\n",
              "             'bühne': 136,\n",
              "             'fahren': 137,\n",
              "             'brille': 138,\n",
              "             'seine': 139,\n",
              "             'herum': 140,\n",
              "             'rennen': 141,\n",
              "             'gehweg': 142,\n",
              "             'kopf': 143,\n",
              "             'sehen': 144,\n",
              "             'er': 145,\n",
              "             'blickt': 146,\n",
              "             'dabei': 147,\n",
              "             'foto': 148,\n",
              "             'seinen': 149,\n",
              "             'weißer': 150,\n",
              "             'des': 151,\n",
              "             'stadt': 152,\n",
              "             'braunen': 153,\n",
              "             'hinunter': 154,\n",
              "             'park': 155,\n",
              "             'liegt': 156,\n",
              "             'laufen': 157,\n",
              "             'versucht': 158,\n",
              "             'arbeitet': 159,\n",
              "             'jeans': 160,\n",
              "             'als': 161,\n",
              "             'bank': 162,\n",
              "             'tragen': 163,\n",
              "             'baby': 164,\n",
              "             'dame': 165,\n",
              "             'wie': 166,\n",
              "             'machen': 167,\n",
              "             'große': 168,\n",
              "             'lächelt': 169,\n",
              "             'schauen': 170,\n",
              "             'brauner': 171,\n",
              "             'ihrem': 172,\n",
              "             'schwarz': 173,\n",
              "             'ältere': 174,\n",
              "             'orangefarbenen': 175,\n",
              "             'ihm': 176,\n",
              "             'junges': 177,\n",
              "             'bürgersteig': 178,\n",
              "             'arbeiten': 179,\n",
              "             'hose': 180,\n",
              "             'zeigt': 181,\n",
              "             'sieht': 182,\n",
              "             'spricht': 183,\n",
              "             'liest': 184,\n",
              "             'unterhalten': 185,\n",
              "             'skateboard': 186,\n",
              "             'halten': 187,\n",
              "             'haaren': 188,\n",
              "             'wand': 189,\n",
              "             'weg': 190,\n",
              "             'viele': 191,\n",
              "             'sonnenbrille': 192,\n",
              "             'zum': 193,\n",
              "             'boot': 194,\n",
              "             'pferd': 195,\n",
              "             'gekleidete': 196,\n",
              "             'seiner': 197,\n",
              "             'hosen': 198,\n",
              "             'rosa': 199,\n",
              "             'tag': 200,\n",
              "             'helm': 201,\n",
              "             'weißem': 202,\n",
              "             'grauen': 203,\n",
              "             'singt': 204,\n",
              "             'ihnen': 205,\n",
              "             'blauem': 206,\n",
              "             'gesicht': 207,\n",
              "             '„': 208,\n",
              "             'bild': 209,\n",
              "             'mantel': 210,\n",
              "             'auto': 211,\n",
              "             'posiert': 212,\n",
              "             'darauf': 213,\n",
              "             'felsen': 214,\n",
              "             'fußball': 215,\n",
              "             'fünf': 216,\n",
              "             'klettert': 217,\n",
              "             'führt': 218,\n",
              "             'shorts': 219,\n",
              "             'befindet': 220,\n",
              "             'einige': 221,\n",
              "             'sand': 222,\n",
              "             'mikrofon': 223,\n",
              "             'baum': 224,\n",
              "             'blauer': 225,\n",
              "             'schwarzem': 226,\n",
              "             'sehr': 227,\n",
              "             'wirft': 228,\n",
              "             'gekleideter': 229,\n",
              "             'band': 230,\n",
              "             'es': 231,\n",
              "             'weiß': 232,\n",
              "             '“': 233,\n",
              "             'blau': 234,\n",
              "             'meer': 235,\n",
              "             'oder': 236,\n",
              "             'rotem': 237,\n",
              "             'isst': 238,\n",
              "             'restaurant': 239,\n",
              "             'wald': 240,\n",
              "             'arbeiter': 241,\n",
              "             'männern': 242,\n",
              "             'schwarze': 243,\n",
              "             'anderer': 244,\n",
              "             'kindern': 245,\n",
              "             'raum': 246,\n",
              "             'wiese': 247,\n",
              "             'fenster': 248,\n",
              "             'langen': 249,\n",
              "             'pullover': 250,\n",
              "             'roter': 251,\n",
              "             'wartet': 252,\n",
              "             'weiße': 253,\n",
              "             'ins': 254,\n",
              "             'anzug': 255,\n",
              "             'bluse': 256,\n",
              "             'gestreiften': 257,\n",
              "             'posieren': 258,\n",
              "             'motorrad': 259,\n",
              "             'haar': 260,\n",
              "             'springen': 261,\n",
              "             'tanzen': 262,\n",
              "             'trikot': 263,\n",
              "             'werden': 264,\n",
              "             'oberkörper': 265,\n",
              "             'voller': 266,\n",
              "             'bereitet': 267,\n",
              "             'stuhl': 268,\n",
              "             'spieler': 269,\n",
              "             'betrachtet': 270,\n",
              "             'rot': 271,\n",
              "             'alter': 272,\n",
              "             'hügel': 273,\n",
              "             'blonde': 274,\n",
              "             'schild': 275,\n",
              "             'zwischen': 276,\n",
              "             'handy': 277,\n",
              "             'oben': 278,\n",
              "             'warten': 279,\n",
              "             'leuten': 280,\n",
              "             'schläft': 281,\n",
              "             'berg': 282,\n",
              "             'zieht': 283,\n",
              "             'ab': 284,\n",
              "             'mütze': 285,\n",
              "             'buch': 286,\n",
              "             'lehnt': 287,\n",
              "             'reitet': 288,\n",
              "             'händen': 289,\n",
              "             'beobachtet': 290,\n",
              "             'maul': 291,\n",
              "             'miteinander': 292,\n",
              "             'stock': 293,\n",
              "             'bäumen': 294,\n",
              "             'fluss': 295,\n",
              "             'ihrer': 296,\n",
              "             'tanzt': 297,\n",
              "             'bauarbeiter': 298,\n",
              "             'kleinkind': 299,\n",
              "             'rucksack': 300,\n",
              "             'arm': 301,\n",
              "             'lächeln': 302,\n",
              "             'schiebt': 303,\n",
              "             'vom': 304,\n",
              "             'befinden': 305,\n",
              "             'gegen': 306,\n",
              "             'haben': 307,\n",
              "             'radfahrer': 308,\n",
              "             'küche': 309,\n",
              "             'see': 310,\n",
              "             'seite': 311,\n",
              "             'spielzeug': 312,\n",
              "             'kurzen': 313,\n",
              "             'schwimmbecken': 314,\n",
              "             'asiatische': 315,\n",
              "             'welle': 316,\n",
              "             'rücken': 317,\n",
              "             'spiel': 318,\n",
              "             'treppe': 319,\n",
              "             'zaun': 320,\n",
              "             'verkauft': 321,\n",
              "             'zur': 322,\n",
              "             'familie': 323,\n",
              "             'fangen': 324,\n",
              "             'jemand': 325,\n",
              "             'mitten': 326,\n",
              "             'trinkt': 327,\n",
              "             'versammelt': 328,\n",
              "             'großer': 329,\n",
              "             'erwachsene': 330,\n",
              "             'rosafarbenen': 331,\n",
              "             'blumen': 332,\n",
              "             'hängt': 333,\n",
              "             'ihn': 334,\n",
              "             'schneidet': 335,\n",
              "             'geschäft': 336,\n",
              "             'gerade': 337,\n",
              "             'markt': 338,\n",
              "             'telefoniert': 339,\n",
              "             'belebten': 340,\n",
              "             'bunten': 341,\n",
              "             'malt': 342,\n",
              "             'spazieren': 343,\n",
              "             'umgeben': 344,\n",
              "             'nimmt': 345,\n",
              "             'reihe': 346,\n",
              "             'blicken': 347,\n",
              "             'gewässer': 348,\n",
              "             'rote': 349,\n",
              "             'schwimmt': 350,\n",
              "             'zug': 351,\n",
              "             'autos': 352,\n",
              "             'bus': 353,\n",
              "             'denen': 354,\n",
              "             'freiem': 355,\n",
              "             'schneebedeckten': 356,\n",
              "             'vielen': 357,\n",
              "             'gekleidet': 358,\n",
              "             'schlägt': 359,\n",
              "             'brücke': 360,\n",
              "             'fuß': 361,\n",
              "             'gebäudes': 362,\n",
              "             'hände': 363,\n",
              "             'mutter': 364,\n",
              "             'sonnigen': 365,\n",
              "             'wagen': 366,\n",
              "             'fliegt': 367,\n",
              "             'himmel': 368,\n",
              "             'publikum': 369,\n",
              "             'bart': 370,\n",
              "             'fußballspieler': 371,\n",
              "             'hebt': 372,\n",
              "             'kämpfen': 373,\n",
              "             'richtung': 374,\n",
              "             'tasche': 375,\n",
              "             'dunklen': 376,\n",
              "             'hemden': 377,\n",
              "             'herunter': 378,\n",
              "             'geländer': 379,\n",
              "             'grünem': 380,\n",
              "             'weste': 381,\n",
              "             'hohen': 382,\n",
              "             'platz': 383,\n",
              "             'asiatischer': 384,\n",
              "             'blondes': 385,\n",
              "             'graffiti': 386,\n",
              "             'haus': 387,\n",
              "             'weißes': 388,\n",
              "             'zuschauer': 389,\n",
              "             'alte': 390,\n",
              "             'kopfbedeckung': 391,\n",
              "             'seil': 392,\n",
              "             'zeitung': 393,\n",
              "             'überqueren': 394,\n",
              "             'mannes': 395,\n",
              "             'hinauf': 396,\n",
              "             'sprung': 397,\n",
              "             'teil': 398,\n",
              "             'zuschauen': 399,\n",
              "             'bereiten': 400,\n",
              "             'musik': 401,\n",
              "             'tritt': 402,\n",
              "             'davon': 403,\n",
              "             'genießt': 404,\n",
              "             'orangen': 405,\n",
              "             'basketball': 406,\n",
              "             'blaue': 407,\n",
              "             'decke': 408,\n",
              "             'hof': 409,\n",
              "             'karierten': 410,\n",
              "             'lacht': 411,\n",
              "             'mittleren': 412,\n",
              "             'sechs': 413,\n",
              "             'shirt': 414,\n",
              "             'benutzt': 415,\n",
              "             'da': 416,\n",
              "             'schirm': 417,\n",
              "             'zuschauern': 418,\n",
              "             'alten': 419,\n",
              "             'fest': 420,\n",
              "             'kunststück': 421,\n",
              "             'mauer': 422,\n",
              "             'menge': 423,\n",
              "             'papier': 424,\n",
              "             'stück': 425,\n",
              "             'einigen': 426,\n",
              "             'großes': 427,\n",
              "             'unterhält': 428,\n",
              "             'alters': 429,\n",
              "             'blick': 430,\n",
              "             'mensch': 431,\n",
              "             'rasen': 432,\n",
              "             'spielplatz': 433,\n",
              "             'zusieht': 434,\n",
              "             'baseballspieler': 435,\n",
              "             'mitte': 436,\n",
              "             'nahe': 437,\n",
              "             'nebeneinander': 438,\n",
              "             'schaukel': 439,\n",
              "             'sofa': 440,\n",
              "             'zuschaut': 441,\n",
              "             'armen': 442,\n",
              "             'lässt': 443,\n",
              "             'nachts': 444,\n",
              "             'trinken': 445,\n",
              "             '–': 446,\n",
              "             'bereit': 447,\n",
              "             'fotos': 448,\n",
              "             'lila': 449,\n",
              "             'pool': 450,\n",
              "             'rock': 451,\n",
              "             'typ': 452,\n",
              "             'zusehen': 453,\n",
              "             'augen': 454,\n",
              "             'dach': 455,\n",
              "             'gegenstand': 456,\n",
              "             'gelber': 457,\n",
              "             'hinten': 458,\n",
              "             'versuchen': 459,\n",
              "             'zigarette': 460,\n",
              "             'bier': 461,\n",
              "             'gibt': 462,\n",
              "             'mehreren': 463,\n",
              "             'scheint': 464,\n",
              "             'sonne': 465,\n",
              "             'beobachten': 466,\n",
              "             'mund': 467,\n",
              "             'surfer': 468,\n",
              "             'treten': 469,\n",
              "             'beide': 470,\n",
              "             'flagge': 471,\n",
              "             'fängt': 472,\n",
              "             'kniet': 473,\n",
              "             'nummer': 474,\n",
              "             'outfit': 475,\n",
              "             'raucht': 476,\n",
              "             'schal': 477,\n",
              "             'uniform': 478,\n",
              "             'öffentlichen': 479,\n",
              "             'betrachten': 480,\n",
              "             'ferne': 481,\n",
              "             'nicht': 482,\n",
              "             'schürze': 483,\n",
              "             'stange': 484,\n",
              "             'stufen': 485,\n",
              "             'trikots': 486,\n",
              "             'verschneiten': 487,\n",
              "             'führen': 488,\n",
              "             'liegen': 489,\n",
              "             'wanderer': 490,\n",
              "             'blonden': 491,\n",
              "             'diese': 492,\n",
              "             'erwachsener': 493,\n",
              "             'frisbee': 494,\n",
              "             'gehsteig': 495,\n",
              "             'rotes': 496,\n",
              "             'außerhalb': 497,\n",
              "             'einander': 498,\n",
              "             'holz': 499,\n",
              "             'lachen': 500,\n",
              "             'rampe': 501,\n",
              "             'snowboarder': 502,\n",
              "             'teenager': 503,\n",
              "             'tennisball': 504,\n",
              "             'unten': 505,\n",
              "             'gemüse': 506,\n",
              "             'u-bahn': 507,\n",
              "             'bett': 508,\n",
              "             'greift': 509,\n",
              "             'männliche': 510,\n",
              "             'reden': 511,\n",
              "             'rutscht': 512,\n",
              "             'veranstaltung': 513,\n",
              "             'aufschrift': 514,\n",
              "             'braune': 515,\n",
              "             'bärtiger': 516,\n",
              "             'fotografiert': 517,\n",
              "             'grün': 518,\n",
              "             'hilft': 519,\n",
              "             'kleidern': 520,\n",
              "             'nacht': 521,\n",
              "             'schwarz-weißer': 522,\n",
              "             'beiden': 523,\n",
              "             'hüten': 524,\n",
              "             'sonnenuntergang': 525,\n",
              "             'surft': 526,\n",
              "             'werfen': 527,\n",
              "             'dass': 528,\n",
              "             'gelbe': 529,\n",
              "             'gelbem': 530,\n",
              "             'grüner': 531,\n",
              "             'haare': 532,\n",
              "             'herr': 533,\n",
              "             'kostümen': 534,\n",
              "             'leiter': 535,\n",
              "             'man': 536,\n",
              "             'musiker': 537,\n",
              "             'skifahrer': 538,\n",
              "             'überquert': 539,\n",
              "             'art': 540,\n",
              "             'damen': 541,\n",
              "             'legt': 542,\n",
              "             'nacktem': 543,\n",
              "             'polizisten': 544,\n",
              "             'statue': 545,\n",
              "             'städtischen': 546,\n",
              "             'ufer': 547,\n",
              "             'versammeln': 548,\n",
              "             'zelt': 549,\n",
              "             'basketballspieler': 550,\n",
              "             'blonder': 551,\n",
              "             'erwachsenen': 552,\n",
              "             'maschine': 553,\n",
              "             'nehmen': 554,\n",
              "             'orange': 555,\n",
              "             'tür': 556,\n",
              "             'bar': 557,\n",
              "             'blaues': 558,\n",
              "             'kommt': 559,\n",
              "             'leine': 560,\n",
              "             'mannschaft': 561,\n",
              "             'rutsche': 562,\n",
              "             'tor': 563,\n",
              "             'brunnen': 564,\n",
              "             'genießen': 565,\n",
              "             'guckt': 566,\n",
              "             'pfad': 567,\n",
              "             'polizist': 568,\n",
              "             'schreibt': 569,\n",
              "             'stellt': 570,\n",
              "             'sweatshirt': 571,\n",
              "             'vater': 572,\n",
              "             'westen': 573,\n",
              "             'asiatischen': 574,\n",
              "             'eimer': 575,\n",
              "             'fisch': 576,\n",
              "             'gelb': 577,\n",
              "             'leeren': 578,\n",
              "             'lesen': 579,\n",
              "             'läufer': 580,\n",
              "             'stühlen': 581,\n",
              "             'braut': 582,\n",
              "             'ende': 583,\n",
              "             'feuer': 584,\n",
              "             'gekleideten': 585,\n",
              "             'gestreiftem': 586,\n",
              "             'getränk': 587,\n",
              "             'grill': 588,\n",
              "             'her': 589,\n",
              "             'inmitten': 590,\n",
              "             'kaufen': 591,\n",
              "             'klettern': 592,\n",
              "             'obst': 593,\n",
              "             'ohne': 594,\n",
              "             'regen': 595,\n",
              "             'schlagzeug': 596,\n",
              "             'sprechen': 597,\n",
              "             'streckt': 598,\n",
              "             'umgebung': 599,\n",
              "             'verschiedene': 600,\n",
              "             'wobei': 601,\n",
              "             'badeanzug': 602,\n",
              "             'eis': 603,\n",
              "             'fahrzeug': 604,\n",
              "             'riesigen': 605,\n",
              "             'schuhen': 606,\n",
              "             'schutzhelm': 607,\n",
              "             'schwingt': 608,\n",
              "             'wellen': 609,\n",
              "             'anderes': 610,\n",
              "             'arme': 611,\n",
              "             'gegend': 612,\n",
              "             'gelbes': 613,\n",
              "             'gemeinsam': 614,\n",
              "             'grauem': 615,\n",
              "             'handschuhen': 616,\n",
              "             'instrument': 617,\n",
              "             'motorradfahrer': 618,\n",
              "             'parade': 619,\n",
              "             'parkplatz': 620,\n",
              "             'regenschirm': 621,\n",
              "             'schlagen': 622,\n",
              "             'singen': 623,\n",
              "             'sohn': 624,\n",
              "             'soldaten': 625,\n",
              "             'trick': 626,\n",
              "             'uniformen': 627,\n",
              "             'älteren': 628,\n",
              "             'bergen': 629,\n",
              "             'gebäuden': 630,\n",
              "             'hört': 631,\n",
              "             'jugendlicher': 632,\n",
              "             'kinderwagen': 633,\n",
              "             'korb': 634,\n",
              "             'offenen': 635,\n",
              "             'schwarzes': 636,\n",
              "             'starrt': 637,\n",
              "             'straßenecke': 638,\n",
              "             'straßenrand': 639,\n",
              "             '\\xa0': 640,\n",
              "             'arbeit': 641,\n",
              "             'baustelle': 642,\n",
              "             'bereich': 643,\n",
              "             'dieser': 644,\n",
              "             'jagt': 645,\n",
              "             'lächelnd': 646,\n",
              "             'mikrophon': 647,\n",
              "             'pinkfarbenen': 648,\n",
              "             'schoß': 649,\n",
              "             'straßen': 650,\n",
              "             'umarmt': 651,\n",
              "             'zurück': 652,\n",
              "             'computer': 653,\n",
              "             'dunkelhäutiger': 654,\n",
              "             'gleich': 655,\n",
              "             'grüne': 656,\n",
              "             'jacken': 657,\n",
              "             'kostüm': 658,\n",
              "             'krawatte': 659,\n",
              "             'laden': 660,\n",
              "             'orangefarbener': 661,\n",
              "             'pause': 662,\n",
              "             'waren': 663,\n",
              "             ' ': 664,\n",
              "             '\"': 665,\n",
              "             'kurz': 666,\n",
              "             'repariert': 667,\n",
              "             'schreibtisch': 668,\n",
              "             'volleyball': 669,\n",
              "             'vordergrund': 670,\n",
              "             'alle': 671,\n",
              "             'baseball': 672,\n",
              "             'ganz': 673,\n",
              "             'garten': 674,\n",
              "             'gegeneinander': 675,\n",
              "             'gekleidetes': 676,\n",
              "             'gut': 677,\n",
              "             'konzert': 678,\n",
              "             'kuchen': 679,\n",
              "             'kurzer': 680,\n",
              "             'putzt': 681,\n",
              "             'schatten': 682,\n",
              "             'vogel': 683,\n",
              "             'asiatisches': 684,\n",
              "             'balanciert': 685,\n",
              "             'bedeckt': 686,\n",
              "             'fahrradfahrer': 687,\n",
              "             'fahrrädern': 688,\n",
              "             'grünes': 689,\n",
              "             'jemandem': 690,\n",
              "             'kunden': 691,\n",
              "             'lächelnde': 692,\n",
              "             'pflanzen': 693,\n",
              "             'sandalen': 694,\n",
              "             'verkaufen': 695,\n",
              "             'beugt': 696,\n",
              "             'bikini': 697,\n",
              "             'erde': 698,\n",
              "             'fell': 699,\n",
              "             'gegenüber': 700,\n",
              "             'land': 701,\n",
              "             'lkw': 702,\n",
              "             'netz': 703,\n",
              "             'party': 704,\n",
              "             'pferden': 705,\n",
              "             'setzt': 706,\n",
              "             'stein': 707,\n",
              "             'stiefeln': 708,\n",
              "             'weibliche': 709,\n",
              "             'winkt': 710,\n",
              "             'ziehen': 711,\n",
              "             'dreht': 712,\n",
              "             'einkaufswagen': 713,\n",
              "             'felswand': 714,\n",
              "             'football': 715,\n",
              "             'football-spieler': 716,\n",
              "             'footballspieler': 717,\n",
              "             'fällt': 718,\n",
              "             'glas': 719,\n",
              "             'halsband': 720,\n",
              "             'klassenzimmer': 721,\n",
              "             'mobiltelefon': 722,\n",
              "             'orangefarbenem': 723,\n",
              "             'reiten': 724,\n",
              "             'schiedsrichter': 725,\n",
              "             'schulter': 726,\n",
              "             'schüler': 727,\n",
              "             'snowboard': 728,\n",
              "             'surfbrett': 729,\n",
              "             'wo': 730,\n",
              "             'badehose': 731,\n",
              "             'belebte': 732,\n",
              "             'dessen': 733,\n",
              "             'hellbrauner': 734,\n",
              "             'höhe': 735,\n",
              "             'schlitten': 736,\n",
              "             'schläger': 737,\n",
              "             'team': 738,\n",
              "             'unbefestigten': 739,\n",
              "             'aussieht': 740,\n",
              "             'bein': 741,\n",
              "             'braunem': 742,\n",
              "             'davor': 743,\n",
              "             'durchs': 744,\n",
              "             'kajak': 745,\n",
              "             'kanu': 746,\n",
              "             'leuchtend': 747,\n",
              "             'oberteilen': 748,\n",
              "             'rad': 749,\n",
              "             'redet': 750,\n",
              "             'schuhe': 751,\n",
              "             'schwimmen': 752,\n",
              "             'seines': 753,\n",
              "             'stand': 754,\n",
              "             'was': 755,\n",
              "             'zeigen': 756,\n",
              "             'ecke': 757,\n",
              "             'küssen': 758,\n",
              "             'küsst': 759,\n",
              "             'loch': 760,\n",
              "             'schlange': 761,\n",
              "             'schnauze': 762,\n",
              "             'spiegel': 763,\n",
              "             'tischen': 764,\n",
              "             'verschiedenen': 765,\n",
              "             'asiatisch': 766,\n",
              "             'base': 767,\n",
              "             'bäume': 768,\n",
              "             'farbenfrohen': 769,\n",
              "             'grasbewachsenen': 770,\n",
              "             'hin': 771,\n",
              "             'kreis': 772,\n",
              "             'künstler': 773,\n",
              "             'laptop': 774,\n",
              "             'lilafarbenen': 775,\n",
              "             'mikroskop': 776,\n",
              "             'männlicher': 777,\n",
              "             'rennstrecke': 778,\n",
              "             'schultern': 779,\n",
              "             'schönen': 780,\n",
              "             'seifenblasen': 781,\n",
              "             'skateboarder': 782,\n",
              "             'spaß': 783,\n",
              "             't-shirts': 784,\n",
              "             'taschen': 785,\n",
              "             'telefon': 786,\n",
              "             'tochter': 787,\n",
              "             'akkordeon': 788,\n",
              "             'flasche': 789,\n",
              "             'gepflasterten': 790,\n",
              "             'gerüst': 791,\n",
              "             'haufen': 792,\n",
              "             'kai': 793,\n",
              "             'kirche': 794,\n",
              "             'kocht': 795,\n",
              "             'spielfeld': 796,\n",
              "             'tanktop': 797,\n",
              "             'tasse': 798,\n",
              "             'zimmer': 799,\n",
              "             'aussehende': 800,\n",
              "             'bedient': 801,\n",
              "             'bemalt': 802,\n",
              "             'café': 803,\n",
              "             'farben': 804,\n",
              "             'freunde': 805,\n",
              "             'freunden': 806,\n",
              "             'gegnerischen': 807,\n",
              "             'hellen': 808,\n",
              "             'hunden': 809,\n",
              "             'kappe': 810,\n",
              "             'küste': 811,\n",
              "             'nur': 812,\n",
              "             'parkbank': 813,\n",
              "             'rodeo': 814,\n",
              "             'schaukelt': 815,\n",
              "             'tennis': 816,\n",
              "             'unterwegs': 817,\n",
              "             'beleuchteten': 818,\n",
              "             'bis': 819,\n",
              "             'braun-weißer': 820,\n",
              "             'damit': 821,\n",
              "             'entspannt': 822,\n",
              "             'fleisch': 823,\n",
              "             'gasse': 824,\n",
              "             'geige': 825,\n",
              "             'grauer': 826,\n",
              "             'helmen': 827,\n",
              "             'katze': 828,\n",
              "             'sachen': 829,\n",
              "             'schaufel': 830,\n",
              "             'schutzhelmen': 831,\n",
              "             'schwimmbrille': 832,\n",
              "             'sieben': 833,\n",
              "             'ski': 834,\n",
              "             'stadion': 835,\n",
              "             'steine': 836,\n",
              "             'teich': 837,\n",
              "             'trampolin': 838,\n",
              "             'umarmen': 839,\n",
              "             'violetten': 840,\n",
              "             'berge': 841,\n",
              "             'cowboy': 842,\n",
              "             'hang': 843,\n",
              "             'holt': 844,\n",
              "             'hüpft': 845,\n",
              "             'jongliert': 846,\n",
              "             'kopfhörer': 847,\n",
              "             'langem': 848,\n",
              "             'maske': 849,\n",
              "             'overall': 850,\n",
              "             'rand': 851,\n",
              "             'schlamm': 852,\n",
              "             'schüssel': 853,\n",
              "             'skiern': 854,\n",
              "             'so': 855,\n",
              "             'steigt': 856,\n",
              "             'strecke': 857,\n",
              "             'tänzer': 858,\n",
              "             'verwendet': 859,\n",
              "             'voll': 860,\n",
              "             ';': 861,\n",
              "             'barfuß': 862,\n",
              "             'braun': 863,\n",
              "             'couch': 864,\n",
              "             'dunkler': 865,\n",
              "             'feldweg': 866,\n",
              "             'flaggen': 867,\n",
              "             'fotografieren': 868,\n",
              "             'fußballspiel': 869,\n",
              "             'kaffee': 870,\n",
              "             'kauft': 871,\n",
              "             'klippe': 872,\n",
              "             'landschaft': 873,\n",
              "             'lastwagen': 874,\n",
              "             'links': 875,\n",
              "             'lächelnder': 876,\n",
              "             'rechts': 877,\n",
              "             'reifen': 878,\n",
              "             'reparieren': 879,\n",
              "             'roller': 880,\n",
              "             'schießt': 881,\n",
              "             'tanz': 882,\n",
              "             'anzügen': 883,\n",
              "             'asiate': 884,\n",
              "             'aussehender': 885,\n",
              "             'bekommt': 886,\n",
              "             'berührt': 887,\n",
              "             'bläst': 888,\n",
              "             'cowboyhut': 889,\n",
              "             'dunkelhäutige': 890,\n",
              "             'fahnen': 891,\n",
              "             'grillt': 892,\n",
              "             'heben': 893,\n",
              "             'hellblauen': 894,\n",
              "             'hockt': 895,\n",
              "             'instrumenten': 896,\n",
              "             'kopftuch': 897,\n",
              "             'objekt': 898,\n",
              "             'ringen': 899,\n",
              "             'ruht': 900,\n",
              "             'schüttelt': 901,\n",
              "             'sitzende': 902,\n",
              "             'teller': 903,\n",
              "             'verfolgt': 904,\n",
              "             'wandert': 905,\n",
              "             'wüste': 906,\n",
              "             'beinen': 907,\n",
              "             'bilder': 908,\n",
              "             'clown': 909,\n",
              "             'flugzeug': 910,\n",
              "             'geschlossenen': 911,\n",
              "             'handtasche': 912,\n",
              "             'hängen': 913,\n",
              "             'instrumente': 914,\n",
              "             'linken': 915,\n",
              "             'mahlzeit': 916,\n",
              "             'metall': 917,\n",
              "             'nase': 918,\n",
              "             'new': 919,\n",
              "             'personengruppe': 920,\n",
              "             'reinigt': 921,\n",
              "             'springbrunnen': 922,\n",
              "             'veranda': 923,\n",
              "             'überfüllten': 924,\n",
              "             'asiaten': 925,\n",
              "             'asiatin': 926,\n",
              "             'auch': 927,\n",
              "             'bauen': 928,\n",
              "             'blatt': 929,\n",
              "             'diesem': 930,\n",
              "             'felsigen': 931,\n",
              "             'geländemotorrad': 932,\n",
              "             'gezogen': 933,\n",
              "             'gucken': 934,\n",
              "             'hauses': 935,\n",
              "             'heraus': 936,\n",
              "             'hinab': 937,\n",
              "             'marathon': 938,\n",
              "             'müll': 939,\n",
              "             'pinkfarbenem': 940,\n",
              "             'salto': 941,\n",
              "             'tennisspieler': 942,\n",
              "             'traditioneller': 943,\n",
              "             'öffnet': 944,\n",
              "             'üben': 945,\n",
              "             'auftritt': 946,\n",
              "             'balkon': 947,\n",
              "             'dieses': 948,\n",
              "             'fahrräder': 949,\n",
              "             'kann': 950,\n",
              "             'kerl': 951,\n",
              "             'lederjacke': 952,\n",
              "             'nachdem': 953,\n",
              "             'reiter': 954,\n",
              "             'rothaarige': 955,\n",
              "             'schneiden': 956,\n",
              "             'schnell': 957,\n",
              "             'steinen': 958,\n",
              "             'sänger': 959,\n",
              "             'taucht': 960,\n",
              "             'umzug': 961,\n",
              "             'untersucht': 962,\n",
              "             'winterkleidung': 963,\n",
              "             'wäscht': 964,\n",
              "             'zeit': 965,\n",
              "             'allein': 966,\n",
              "             'amerikanische': 967,\n",
              "             'bach': 968,\n",
              "             'bahn': 969,\n",
              "             'beieinander': 970,\n",
              "             'bunte': 971,\n",
              "             'finger': 972,\n",
              "             'gebiet': 973,\n",
              "             'geld': 974,\n",
              "             'gelegt': 975,\n",
              "             'gießt': 976,\n",
              "             'hellbraunen': 977,\n",
              "             'kickt': 978,\n",
              "             'kurve': 979,\n",
              "             'passanten': 980,\n",
              "             'pferde': 981,\n",
              "             'schießen': 982,\n",
              "             'schlafen': 983,\n",
              "             'schlauch': 984,\n",
              "             'sitzender': 985,\n",
              "             'skateboardfahrer': 986,\n",
              "             'teams': 987,\n",
              "             'teppich': 988,\n",
              "             'terrasse': 989,\n",
              "             'tuch': 990,\n",
              "             'vollen': 991,\n",
              "             'weitere': 992,\n",
              "             'wurde': 993,\n",
              "             'wurf': 994,\n",
              "             'zunge': 995,\n",
              "             'zähne': 996,\n",
              "             'übt': 997,\n",
              "             'ausrüstung': 998,\n",
              "             'beton': 999,\n",
              "             ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na0QTYBBP3nx"
      },
      "source": [
        "Once these lines of code have been run, ``SRC.vocab.stoi`` will  be a\n",
        "dictionary with the tokens in the vocabulary as keys and their\n",
        "corresponding indices as values; ``SRC.vocab.itos`` will be the same\n",
        "dictionary with the keys and values swapped. We won't make extensive\n",
        "use of this fact in this tutorial, but this will likely be useful in\n",
        "other NLP tasks you'll encounter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwYwQWS7P3ny"
      },
      "source": [
        "``BucketIterator``\n",
        "----------------\n",
        "The last ``torchtext`` specific feature we'll use is the ``BucketIterator``,\n",
        "which is easy to use since it takes a ``TranslationDataset`` as its\n",
        "first argument. Specifically, as the docs say:\n",
        "Defines an iterator that batches examples of similar lengths together.\n",
        "Minimizes amount of padding needed while producing freshly shuffled\n",
        "batches for each new epoch. See pool for the bucketing procedure used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eJ77fyFP3ny",
        "outputId": "2f52d1a1-ba3d-48d7-c088-f4e9b841445f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczFfPlIP3n0"
      },
      "source": [
        "These iterators can be called just like ``DataLoader``s; below, in\n",
        "the ``train`` and ``evaluate`` functions, they are called simply with:\n",
        "\n",
        "::\n",
        "\n",
        "   for i, batch in enumerate(iterator):\n",
        "\n",
        "Each ``batch`` then has ``src`` and ``trg`` attributes:\n",
        "\n",
        "::\n",
        "\n",
        "   src = batch.src\n",
        "   trg = batch.trg\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_l3kpCHP3n0"
      },
      "source": [
        "Defining our ``nn.Module`` and ``Optimizer``\n",
        "----------------\n",
        "That's mostly it from a ``torchtext`` perspecive: with the dataset built\n",
        "and the iterator defined, the rest of this tutorial simply defines our\n",
        "model as an ``nn.Module``, along with an ``Optimizer``, and then trains it.\n",
        "\n",
        "Our model specifically, follows the architecture described\n",
        "`here <https://arxiv.org/abs/1409.0473>`__ (you can find a\n",
        "significantly more commented version\n",
        "`here <https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb>`__).\n",
        "\n",
        "Note: this model is just an example model that can be used for language\n",
        "translation; we choose it because it is a standard model for the task,\n",
        "not because it is the recommended model to use for translation. As you're\n",
        "likely aware, state-of-the-art models are currently based on Transformers;\n",
        "you can see PyTorch's capabilities for implementing Transformer layers\n",
        "`here <https://pytorch.org/docs/stable/nn.html#transformer-layers>`__; and\n",
        "in particular, the \"attention\" used in the model below is different from\n",
        "the multi-headed self-attention present in a transformer model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8pVyT5RP3n1",
        "outputId": "ea2a40b2-5488-4a3c-cb0a-76faad0091b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,856,685 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRV90_V2P3n2"
      },
      "source": [
        "Note: when scoring the performance of a language translation model in\n",
        "particular, we have to tell the ``nn.CrossEntropyLoss`` function to\n",
        "ignore the indices where the target is simply padding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5yFf0DNP3n3"
      },
      "source": [
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th8g6MBhP3n5"
      },
      "source": [
        "Finally, we can train and evaluate this model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDHlMAcbP3n5",
        "outputId": "498bbe6f-31b9-4bdd-c217-611652fe3138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: BucketIterator,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: BucketIterator,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 29s\n",
            "\tTrain Loss: 5.674 | Train PPL: 291.080\n",
            "\t Val. Loss: 5.242 |  Val. PPL: 188.990\n",
            "Epoch: 02 | Time: 0m 29s\n",
            "\tTrain Loss: 5.011 | Train PPL: 150.043\n",
            "\t Val. Loss: 5.055 |  Val. PPL: 156.876\n",
            "Epoch: 03 | Time: 0m 29s\n",
            "\tTrain Loss: 4.764 | Train PPL: 117.178\n",
            "\t Val. Loss: 4.992 |  Val. PPL: 147.204\n",
            "Epoch: 04 | Time: 0m 29s\n",
            "\tTrain Loss: 4.631 | Train PPL: 102.603\n",
            "\t Val. Loss: 5.093 |  Val. PPL: 162.869\n",
            "Epoch: 05 | Time: 0m 29s\n",
            "\tTrain Loss: 4.504 | Train PPL:  90.368\n",
            "\t Val. Loss: 5.039 |  Val. PPL: 154.309\n",
            "Epoch: 06 | Time: 0m 29s\n",
            "\tTrain Loss: 4.401 | Train PPL:  81.556\n",
            "\t Val. Loss: 4.892 |  Val. PPL: 133.189\n",
            "Epoch: 07 | Time: 0m 29s\n",
            "\tTrain Loss: 4.311 | Train PPL:  74.479\n",
            "\t Val. Loss: 4.762 |  Val. PPL: 117.007\n",
            "Epoch: 08 | Time: 0m 29s\n",
            "\tTrain Loss: 4.239 | Train PPL:  69.373\n",
            "\t Val. Loss: 4.734 |  Val. PPL: 113.698\n",
            "Epoch: 09 | Time: 0m 29s\n",
            "\tTrain Loss: 4.168 | Train PPL:  64.603\n",
            "\t Val. Loss: 4.731 |  Val. PPL: 113.449\n",
            "Epoch: 10 | Time: 0m 29s\n",
            "\tTrain Loss: 4.093 | Train PPL:  59.945\n",
            "\t Val. Loss: 4.746 |  Val. PPL: 115.118\n",
            "| Test Loss: 4.805 | Test PPL: 122.159 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNwv1vdcP3n7"
      },
      "source": [
        "Next steps\n",
        "--------------\n",
        "\n",
        "- Check out the rest of Ben Trevett's tutorials using ``torchtext``\n",
        "  `here <https://github.com/bentrevett/>`__\n",
        "- Stay tuned for a tutorial using other ``torchtext`` features along\n",
        "  with ``nn.Transformer`` for language modeling via next word prediction!\n",
        "\n",
        "\n"
      ]
    }
  ]
}